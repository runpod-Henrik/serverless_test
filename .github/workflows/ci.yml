name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  lint-and-type-check:
    name: Lint and Type Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Validate GitHub Actions workflows
        continue-on-error: true
        uses: docker://rhysd/actionlint:latest
        with:
          args: -color -verbose

      - name: Run ruff linter
        id: ruff-lint
        continue-on-error: true
        run: |
          set +e
          ruff check . --output-format=github > ruff-lint.txt 2>&1
          RESULT=$?
          set -e
          echo "exit_code=$RESULT" >> "$GITHUB_OUTPUT"

      - name: Run ruff formatter check
        id: ruff-format
        continue-on-error: true
        run: |
          set +e
          ruff format --check . > ruff-format.txt 2>&1
          RESULT=$?
          set -e
          echo "exit_code=$RESULT" >> "$GITHUB_OUTPUT"
          if [ "$RESULT" -ne 0 ]; then
            echo "## Formatting Errors" >> ruff-format.txt
            ruff format --check . --diff >> ruff-format.txt 2>&1 || true
          fi

      - name: Run mypy type checking
        id: mypy
        continue-on-error: true
        run: |
          set +e
          mypy worker.py config.py database.py > mypy.txt 2>&1
          RESULT=$?
          set -e
          echo "exit_code=$RESULT" >> "$GITHUB_OUTPUT"

      - name: Generate lint and type check summary
        if: always()
        run: |
          # Determine status icons
          if [ "${{ steps.ruff-lint.outputs.exit_code }}" = "0" ]; then
            LINT_STATUS="âœ… Passed"
          else
            LINT_STATUS="âŒ Failed"
          fi

          if [ "${{ steps.ruff-format.outputs.exit_code }}" = "0" ]; then
            FORMAT_STATUS="âœ… Passed"
          else
            FORMAT_STATUS="âŒ Failed"
          fi

          if [ "${{ steps.mypy.outputs.exit_code }}" = "0" ]; then
            MYPY_STATUS="âœ… Passed"
          else
            MYPY_STATUS="âŒ Failed"
          fi

          # Generate summary
          cat >> "$GITHUB_STEP_SUMMARY" << EOF
          ## Code Quality Summary

          | Check | Status |
          |-------|--------|
          | ðŸ” Ruff Linting | $LINT_STATUS |
          | ðŸ“ Code Formatting | $FORMAT_STATUS |
          | ðŸ”’ Type Checking | $MYPY_STATUS |
          EOF

          # Add error details if any check failed
          if [ "${{ steps.ruff-lint.outputs.exit_code }}" != "0" ] && [ -f ruff-lint.txt ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "### ðŸ” Linting Errors" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
            cat ruff-lint.txt >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          fi

          if [ "${{ steps.ruff-format.outputs.exit_code }}" != "0" ] && [ -f ruff-format.txt ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "### ðŸ“ Formatting Errors" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
            cat ruff-format.txt >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          fi

          if [ "${{ steps.mypy.outputs.exit_code }}" != "0" ] && [ -f mypy.txt ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "### ðŸ”’ Type Checking Errors" >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
            cat mypy.txt >> "$GITHUB_STEP_SUMMARY"
            echo '```' >> "$GITHUB_STEP_SUMMARY"
          fi

          # All checks passed message
          if [ "${{ steps.ruff-lint.outputs.exit_code }}" = "0" ] && \
             [ "${{ steps.ruff-format.outputs.exit_code }}" = "0" ] && \
             [ "${{ steps.mypy.outputs.exit_code }}" = "0" ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "All code quality checks completed successfully!" >> "$GITHUB_STEP_SUMMARY"
          fi

          # Fail the workflow if any check failed
          if [ "${{ steps.ruff-lint.outputs.exit_code }}" != "0" ] || \
             [ "${{ steps.ruff-format.outputs.exit_code }}" != "0" ] || \
             [ "${{ steps.mypy.outputs.exit_code }}" != "0" ]; then
            exit 1
          fi

  test:
    name: Test Suite
    runs-on: ubuntu-latest
    needs: lint-and-type-check

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for git diff comparisons

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Get last successful run
        id: last-success
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const runs = await github.rest.actions.listWorkflowRuns({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'ci.yml',
              branch: context.ref.replace('refs/heads/', ''),
              status: 'success',
              per_page: 1
            });

            if (runs.data.workflow_runs.length > 0) {
              const lastSuccess = runs.data.workflow_runs[0];
              core.setOutput('sha', lastSuccess.head_sha);
              core.setOutput('run_id', lastSuccess.id);
              core.setOutput('run_number', lastSuccess.run_number);
              core.setOutput('created_at', lastSuccess.created_at);
            } else {
              core.setOutput('sha', '');
              core.setOutput('run_id', '');
              core.setOutput('run_number', '');
              core.setOutput('created_at', '');
            }

      - name: Get previous coverage
        id: prev-coverage
        if: always() && steps.last-success.outputs.run_id != ''
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            try {
              const runId = parseInt('${{ steps.last-success.outputs.run_id }}', 10);
              const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: runId
              });

              const coverageArtifact = artifacts.data.artifacts.find(
                a => a.name === 'coverage-report'
              );

              if (coverageArtifact) {
                const download = await github.rest.actions.downloadArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: coverageArtifact.id,
                  archive_format: 'zip'
                });

                // Save artifact data for extraction
                const fs = require('fs');
                fs.writeFileSync('previous-coverage.zip', Buffer.from(download.data));

                // Extract and read coverage
                const { execSync } = require('child_process');
                execSync('unzip -q previous-coverage.zip -d previous-coverage || true');

                if (fs.existsSync('previous-coverage/coverage.xml')) {
                  const xml = fs.readFileSync('previous-coverage/coverage.xml', 'utf8');
                  const match = xml.match(/line-rate="([0-9.]+)"/);
                  if (match) {
                    const coverage = (parseFloat(match[1]) * 100).toFixed(2);
                    core.setOutput('coverage', coverage);
                  } else {
                    core.setOutput('coverage', '0');
                  }
                } else {
                  core.setOutput('coverage', '0');
                }
              } else {
                core.setOutput('coverage', '0');
              }
            } catch (error) {
              console.log('Could not fetch previous coverage:', error.message);
              core.setOutput('coverage', '0');
            }

      - name: Run tests with coverage
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest tests/test_config.py tests/test_database.py tests/test_worker.py \
            -v \
            --tb=short \
            --cov=worker \
            --cov=config \
            --cov=database \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-report=html \
            --cov-fail-under=90 \
            --junit-xml=test-results.xml

      - name: Analyze code changes
        id: changes
        if: always() && steps.last-success.outputs.sha != ''
        continue-on-error: true
        run: |
          LAST_SHA="${{ steps.last-success.outputs.sha }}"

          # Verify the commit exists
          if ! git cat-file -e "$LAST_SHA^{commit}" 2>/dev/null; then
            echo "Warning: Last successful commit $LAST_SHA not found in history"
            echo "total_changed=0" >> "$GITHUB_OUTPUT"
            echo "python_changed=0" >> "$GITHUB_OUTPUT"
            echo "workflow_changed=0" >> "$GITHUB_OUTPUT"
            echo "commit_count=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Get changed files
          git diff --name-only "$LAST_SHA" HEAD > changed_files.txt

          # Get statistics
          TOTAL_CHANGED=$(wc -l < changed_files.txt | tr -d ' ')
          PYTHON_CHANGED=$(grep "\.py$" changed_files.txt | wc -l | tr -d ' ')
          WORKFLOW_CHANGED=$(grep "\.github/workflows" changed_files.txt | wc -l | tr -d ' ')

          # Get detailed diff stats
          git diff --stat "$LAST_SHA" HEAD > diff_stats.txt

          # Get commit information
          git log --oneline --no-decorate "$LAST_SHA..HEAD" > commits_oneline.txt
          git log --format="%h|%an|%ae|%ar|%s" "$LAST_SHA..HEAD" > commits_detailed.txt
          COMMIT_COUNT=$(git rev-list --count "$LAST_SHA..HEAD")

          echo "total_changed=$TOTAL_CHANGED" >> "$GITHUB_OUTPUT"
          echo "python_changed=$PYTHON_CHANGED" >> "$GITHUB_OUTPUT"
          echo "workflow_changed=$WORKFLOW_CHANGED" >> "$GITHUB_OUTPUT"
          echo "last_success_sha=$LAST_SHA" >> "$GITHUB_OUTPUT"
          echo "commit_count=$COMMIT_COUNT" >> "$GITHUB_OUTPUT"

      - name: Generate test summary
        if: always()
        env:
          LAST_SUCCESS_SHA: ${{ steps.changes.outputs.last_success_sha }}
          PREV_COVERAGE: ${{ steps.prev-coverage.outputs.coverage }}
        run: |
          python << 'EOF'
          import xml.etree.ElementTree as ET
          import os
          import subprocess

          # Parse test results
          tree = ET.parse('test-results.xml')
          root = tree.getroot()

          # Get testsuite element (root is testsuites, we need testsuite)
          testsuite = root.find('testsuite')
          if testsuite is None:
              testsuite = root  # Fallback if structure is different

          # Extract statistics
          tests = int(testsuite.attrib.get('tests', 0))
          failures = int(testsuite.attrib.get('failures', 0))
          errors = int(testsuite.attrib.get('errors', 0))
          skipped = int(testsuite.attrib.get('skipped', 0))
          time = float(testsuite.attrib.get('time', '0'))
          passed = tests - failures - errors - skipped

          # Parse coverage from coverage.xml
          try:
              cov_tree = ET.parse('coverage.xml')
              cov_root = cov_tree.getroot()
              line_rate = cov_root.attrib.get('line-rate', '0')
              coverage = float(line_rate) * 100.0
          except Exception as e:
              print(f"Coverage parsing error: {e}")
              coverage = 0.0

          # Get previous coverage for delta calculation
          try:
              prev_cov_str = os.environ.get('PREV_COVERAGE', '0')
              previous_coverage = float(prev_cov_str) if prev_cov_str else 0.0
          except Exception as e:
              print(f"Previous coverage parsing error: {e}")
              previous_coverage = 0.0

          # Write to GitHub summary
          with open(os.environ['GITHUB_STEP_SUMMARY'], 'a') as f:
              f.write('## Test Results Summary\n\n')

              # Overall status
              if failures + errors == 0:
                  f.write('âœ… **All tests passed!**\n\n')
              else:
                  f.write(f'âŒ **{failures + errors} test(s) failed**\n\n')

              # Show changes since last success (if available)
              last_success_sha = os.environ.get('LAST_SUCCESS_SHA', '')
              if last_success_sha and os.path.exists('changed_files.txt'):
                  f.write('### ðŸ“ Changes Since Last Successful Run\n\n')

                  # Read changed files
                  with open('changed_files.txt') as cf:
                      changed_files = [line.strip() for line in cf if line.strip()]

                  total_changed = len(changed_files)
                  python_files = [f for f in changed_files if f.endswith('.py')]
                  workflow_files = [f for f in changed_files if '.github/workflows' in f]
                  test_files = [f for f in changed_files if 'test' in f.lower() and f.endswith('.py')]

                  # Show commit information
                  if os.path.exists('commits_detailed.txt'):
                      with open('commits_detailed.txt') as cm:
                          commits = [line.strip() for line in cm if line.strip()]

                      f.write(f'**Commits:** {len(commits)} new commit(s)\n')
                      f.write(f'**Comparing:** `{last_success_sha[:7]}...HEAD`\n\n')

                      if commits:
                          f.write('**Recent Commits:**\n\n')
                          f.write('| Commit | Author | Message |\n')
                          f.write('|--------|--------|----------|\n')
                          for commit in commits[:5]:
                              parts = commit.split('|')
                              if len(parts) >= 5:
                                  sha, author, email, commit_time, message = parts[0], parts[1], parts[2], parts[3], '|'.join(parts[4:])
                                  # Truncate long messages
                                  if len(message) > 60:
                                      message = message[:57] + '...'
                                  f.write(f'| `{sha}` | {author} | {message} |\n')
                          if len(commits) > 5:
                              f.write(f'\n*... and {len(commits) - 5} more commits*\n')
                          f.write('\n')
                  else:
                      f.write(f'**Comparing:** `{last_success_sha[:7]}...HEAD`\n\n')
                  f.write('| Category | Count |\n')
                  f.write('|----------|-------|\n')
                  f.write(f'| Total Files Changed | {total_changed} |\n')
                  f.write(f'| Python Files | {len(python_files)} |\n')
                  f.write(f'| Test Files | {len(test_files)} |\n')
                  f.write(f'| Workflow Files | {len(workflow_files)} |\n\n')

                  # Show Python files changed
                  if python_files:
                      f.write('**Python Files Changed:**\n')
                      for pf in python_files[:10]:
                          f.write(f'- `{pf}`\n')
                      if len(python_files) > 10:
                          f.write(f'- ... and {len(python_files) - 10} more\n')
                      f.write('\n')

                  # Show diff stats
                  if os.path.exists('diff_stats.txt'):
                      try:
                          with open('diff_stats.txt') as ds:
                              diff_stats = ds.read().strip()
                          if diff_stats:
                              f.write('<details>\n<summary>ðŸ“Š Detailed Diff Statistics</summary>\n\n')
                              f.write('```\n')
                              f.write(diff_stats[:1000])  # Limit size
                              f.write('\n```\n</details>\n\n')
                      except:
                          pass

                  # Identify potentially affected tests
                  if failures + errors > 0 and python_files:
                      f.write('**Potential Breaking Changes:**\n')
                      core_files = [file for file in python_files if file in ['worker.py', 'config.py', 'database.py']]
                      if core_files:
                          core_files_str = ", ".join([f"`{file}`" for file in core_files])
                          f.write(f'- âš ï¸ Core modules modified: {core_files_str}\n')
                      if test_files:
                          f.write(f'- ðŸ§ª Test files modified: {len(test_files)} file(s)\n')
                      f.write('\n')

              # Calculate coverage delta
              coverage_delta = None
              coverage_delta_str = ""
              if previous_coverage is not None and previous_coverage > 0:
                  coverage_delta = float(coverage) - float(previous_coverage)
                  if coverage_delta > 0:
                      coverage_delta_str = f" (ðŸŸ¢ +{coverage_delta:.1f}%)"
                  elif coverage_delta < 0:
                      coverage_delta_str = f" (ðŸ”´ {coverage_delta:.1f}%)"
                  else:
                      coverage_delta_str = " (âž¡ï¸ no change)"

              # Force all numeric values to correct types before displaying
              tests = int(tests)
              passed = int(passed)
              failures = int(failures)
              errors = int(errors)
              skipped = int(skipped)
              time = float(time)
              coverage = float(coverage)

              # Statistics table
              f.write('| Metric | Value |\n')
              f.write('|--------|-------|\n')
              f.write(f'| Total Tests | {tests} |\n')
              f.write(f'| âœ… Passed | {passed} |\n')
              f.write(f'| âŒ Failed | {failures} |\n')
              f.write(f'| âš ï¸ Errors | {errors} |\n')
              f.write(f'| â­ï¸ Skipped | {skipped} |\n')
              f.write(f'| â±ï¸ Duration | {time:.2f}s |\n')
              f.write(f'| ðŸ“Š Coverage | {coverage:.1f}%{coverage_delta_str} |\n\n')

              # Failed tests details
              if failures + errors > 0:
                  f.write('### Failed Tests\n\n')
                  for testcase in testsuite.iter('testcase'):
                      failure = testcase.find('failure')
                      error = testcase.find('error')

                      if failure is not None or error is not None:
                          classname = testcase.attrib.get('classname', '')
                          name = testcase.attrib.get('name', '')
                          test_time = testcase.attrib.get('time', '0')

                          f.write(f'#### âŒ `{classname}.{name}`\n\n')
                          # Safely convert test time to float
                          try:
                              test_time_float = float(test_time)
                              f.write(f'- **Duration:** {test_time_float:.2f}s\n')
                          except (ValueError, TypeError):
                              f.write(f'- **Duration:** {test_time}\n')

                          if failure is not None:
                              message = failure.attrib.get('message', 'No message')
                              f.write(f'- **Failure:** {message}\n')
                              if failure.text:
                                  f.write(f'\n```\n{failure.text[:500]}\n```\n\n')

                          if error is not None:
                              message = error.attrib.get('message', 'No message')
                              f.write(f'- **Error:** {message}\n')
                              if error.text:
                                  f.write(f'\n```\n{error.text[:500]}\n```\n\n')

              # Coverage status
              if coverage >= 95:
                  f.write('### ðŸŸ¢ Coverage Status: Excellent (â‰¥95%)\n')
              elif coverage >= 90:
                  f.write('### ðŸŸ¡ Coverage Status: Good (â‰¥90%)\n')
              else:
                  f.write('### ðŸ”´ Coverage Status: Needs Improvement (<90%)\n')

              # Highlight negative coverage delta
              if coverage_delta is not None and coverage_delta < 0:
                  f.write(f'\nâš ï¸ **Coverage decreased by {abs(coverage_delta):.1f}%** ')
                  f.write(f'(was {previous_coverage:.1f}%, now {coverage:.1f}%)\n')
          EOF

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            htmlcov/
            coverage.xml

      - name: Upload test results
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            .pytest_cache/
            test-results/

      - name: Comment coverage on PR
        if: github.event_name == 'pull_request'
        uses: py-cov-action/python-coverage-comment-action@v3
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          MINIMUM_GREEN: 95
          MINIMUM_ORANGE: 90
